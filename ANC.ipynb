{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "maternal_dataset = pd.read_csv(\"Maternal Health Risk Data Set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "maternal_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "maternal_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the RiskLevel to numerical values\n",
    "risk_mapping = {'Low': 0, 'Mid': 1, 'High': 2}\n",
    "maternal_dataset['RiskLevel'] = maternal_dataset['RiskLevel'].map(risk_mapping)\n",
    "\n",
    "# Check the result\n",
    "print(maternal_dataset['RiskLevel'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "maternal_dataset = pd.read_csv(\"Maternal Health Risk Data Set.csv\")\n",
    "maternal_dataset['RiskLevel'] = maternal_dataset['RiskLevel'].astype(str).str.strip().str.lower()\n",
    "print(maternal_dataset['RiskLevel'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_mapping = {'low risk': 0, 'mid risk': 1, 'high risk': 2}\n",
    "maternal_dataset['RiskLevel'] = maternal_dataset['RiskLevel'].map(risk_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(maternal_dataset['RiskLevel'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = maternal_dataset.drop('RiskLevel', axis=1)  # All columns except the target\n",
    "y = maternal_dataset['RiskLevel']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the dataset and scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)   # Fit & transform training features\n",
    "X_test_scaled = scaler.transform(X_test) # Only transform test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_scaled[:5])  # the first 5 rows of the scaled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "log_reg = LogisticRegression(max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(\"Logistic Regression model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_logreg = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_logreg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "y_pred_logreg = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_logreg)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Logistic Regression - Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns  # make sure X is a DataFrame\n",
    "coefficients = log_reg.coef_\n",
    "print(feature_names)\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each class's coefficients\n",
    "for i in range(coefficients.shape[0]):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.barh(feature_names, coefficients[i])\n",
    "    plt.title(f'Logistic Regression Coefficients for Class {i}')\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "dt_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data\n",
    "y_pred_dt = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "confusion_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "report_dt = classification_report(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"Decision Tree Accuracy:\", accuracy_dt)\n",
    "print(\"Confusion Matrix:\\n\", confusion_dt)\n",
    "print(\"Classification Report:\\n\", report_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))  # Adjust size as needed\n",
    "plot_tree(dt_model, feature_names=X.columns, class_names=[\"Low\", \"Mid\", \"High\"],\n",
    "          filled=True, rounded=True, fontsize=10)\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on training data\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance and display \n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Confusion Matrix:\\n\", cm_rf)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = rf_model.feature_importances_\n",
    "feature_names = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for better plotting\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    data=importance_df,\n",
    "    hue='Feature',  # Assign hue\n",
    "    palette='viridis',\n",
    "    dodge=False,    # Avoid shifting bars\n",
    "    legend=False    # Turn off legend since hue is same as y\n",
    ")\n",
    "plt.title('Machine Learning Model-Random Forest')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and display report\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the trained model\n",
    "importances = xgb_model.feature_importances_\n",
    "features = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for easy plotting\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')\n",
    "plt.title('Machine Learning Model - XGBoost')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel='rbf', C=1, gamma='scale', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('SVM Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA for 2D visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM model on 2D PCA data\n",
    "svm_model = SVC(kernel='linear', C=1, random_state=42)\n",
    "svm_model.fit(X_train_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision boundaries\n",
    "def plot_svm_decision_boundary(model, X, y):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                         np.arange(y_min, y_max, 0.1))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='viridis')\n",
    "    sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, palette='deep', edgecolor='k')\n",
    "    plt.title(\"SVM Decision Boundary (PCA 2D Projection)\")\n",
    "    plt.xlabel(\"Principal Component 1\")\n",
    "    plt.ylabel(\"Principal Component 2\")\n",
    "    plt.legend(title=\"Risk Level\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plot_svm_decision_boundary(svm_model, X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance data\n",
    "data = {\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost', 'SVM'],\n",
    "    'Accuracy': [0.67, 0.82, 0.81, 0.86, 0.58],\n",
    "    'Precision': [0.67, 0.82, 0.82, 0.87, 0.63],\n",
    "    'Recall': [0.67, 0.82, 0.82, 0.86, 0.58],\n",
    "    'F1-Score': [0.64, 0.82, 0.81, 0.86, 0.57]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "df.set_index('Model').plot(kind='bar', ax=ax)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"Maternal Health Risk Data Set.csv\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Select only the clinical measurements (exclude RiskLevel)\n",
    "clinical_vars = ['Age', 'SystolicBP', 'DiastolicBP', 'BS', 'BodyTemp', 'HeartRate']\n",
    "df_clinical = df[clinical_vars]\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = df_clinical.corr()\n",
    "\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualization\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix of Clinical Measurements')\n",
    "plt.tight_layout()  # Prevent label cutoff\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('Maternal Health Risk Data Set.csv')\n",
    "\n",
    "# Feature engineering\n",
    "df['BP_Category'] = pd.cut(df['SystolicBP'], \n",
    "                         bins=[0, 90, 120, 140, 200],\n",
    "                         labels=['Low', 'Normal', 'Pre-High', 'High'])\n",
    "\n",
    "# Convert to numerical\n",
    "risk_mapping = {'low risk': 0, 'mid risk': 1, 'high risk': 2}\n",
    "df['RiskLevel_encoded'] = df['RiskLevel'].map(risk_mapping)\n",
    "# 2. Define features\n",
    "\n",
    "numerical_features = ['Age', 'SystolicBP', 'DiastolicBP', 'BS', 'BodyTemp', 'HeartRate']\n",
    "categorical_features = ['BP_Category']\n",
    "\n",
    "# Split data - 80% for training, 20% for testing\n",
    "X = df[numerical_features + categorical_features]\n",
    "y = df['RiskLevel_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,  # 20% for testing\n",
    "    random_state=42,\n",
    "    stratify=y  # Maintain class distribution\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 3. Create preprocessing pipeline with proper encoding\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_features),\n",
    "    ('cat', OneHotEncoder(), categorical_features)\n",
    "])\n",
    "\n",
    "# 4. Train and save both models (using only X_train, y_train)\n",
    "models = {\n",
    "    # 'random_forest': Pipeline([\n",
    "    #     ('preprocessor', preprocessor),\n",
    "    #     ('classifier', RandomForestClassifier(random_state=42))\n",
    "    # ]),\n",
    "    'xgboost': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', XGBClassifier(random_state=42, eval_metric='mlogloss'))\n",
    "    ])\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Only train on 80% of the data\n",
    "    save_path = Path('deployment') / f'{name}_pipeline.pkl'\n",
    "    joblib.dump(model, save_path)\n",
    "    \n",
    "    # Optional: Evaluate on test set\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    # print(f\"{name} test accuracy: {test_score:.2f}\")\n",
    "\n",
    "# 5. Prediction function remains the same\n",
    "def predict_risk_level(age, systolic_bp, diastolic_bp, bs, body_temp, heart_rate, model_type='xgboost'):\n",
    "    \"\"\"Predict using either XGBoost (default) or Random Forest\"\"\"\n",
    "    # Load the selected pipeline\n",
    "    save_path = Path('deployment') / f'{model_type}_pipeline.pkl'\n",
    "    pipeline = joblib.load(save_path)\n",
    "    \n",
    "    # Create input DataFrame (with BP category)\n",
    "    input_df = pd.DataFrame([[age, systolic_bp, diastolic_bp, bs, body_temp, heart_rate]],\n",
    "                          columns=numerical_features)\n",
    "    \n",
    "    # Add BP category (same logic as training)\n",
    "    bp_val = systolic_bp\n",
    "    if bp_val < 90: bp_cat = 'Low'\n",
    "    elif bp_val < 120: bp_cat = 'Normal'\n",
    "    elif bp_val < 140: bp_cat = 'Pre-High'\n",
    "    else: bp_cat = 'High'\n",
    "    input_df['BP_Category'] = bp_cat\n",
    "    \n",
    "    # Predict and return\n",
    "    prediction = pipeline.predict(input_df)[0]\n",
    "    return ['low risk', 'mid risk', 'high risk'][prediction]\n",
    "\n",
    "# Example usage\n",
    "print(\"XGBoost prediction:\", predict_risk_level(35,120,60,6.1,98.0,76))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "This is to test the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://127.0.0.1:5000/predict-api'\n",
    "data = {'Age': 25,'SystolicBP':130,'DiastolicBP':80,'BS':15,'BodyTemp':98.0,'HeartRate':86}  # example input\n",
    "response = requests.post(url, json=data)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
